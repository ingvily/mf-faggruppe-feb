{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vi trenger en klassifikator som kan lagre det den lærer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class classifier:\n",
    "    def __init__(self, getfeatures, filename=None):\n",
    "        self.fc = {}\n",
    "        self.cc = {}\n",
    "        self.getfeatures = getfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fc lagrer antall ganger en feature forekommer i en gitt klasse, og cc lagrer hvor mange ganger en klasse har blitt brukt.\n",
    "\n",
    "Dersom klassifikatoren trenes på setningen \"i liked the Da Vinci Code a lot\" med klassen \"positive\", vil fc bli `{'i': {'positive': 1, 'negative': 0}, 'liked': {'positive': 1, 'negative': 0}, 'the': {'positive': 1, 'negative': 0}, 'Da': {'positive': 1, 'negative': 0}, ...}`\n",
    "\n",
    "Vi legger til følgende hjelpemetoder for å oppdatere/lese fc og cc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-79fee6e93c8e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-79fee6e93c8e>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def incf(self, f, cat):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "        # Øk feature-counten for en klasse\n",
    "    def incf(self, f, cat):\n",
    "        self.fc.setdefault(f, {})\n",
    "        self.fc[f].setdefault(cat, 0)\n",
    "        self.fc[f][cat] += 1\n",
    "\n",
    "\n",
    "        # Øk counten for en klasse/kategori\n",
    "    def incc(self, cat):\n",
    "        self.cc.setdefault(cat, 0)\n",
    "        self.cc[cat] += 1\n",
    "\n",
    "\n",
    "        # Feature-count i en kategori\n",
    "    def fcount(self, f, cat):\n",
    "        if f in self.fc and cat in self.fc[f]:\n",
    "            return float(self.fc[f][cat])\n",
    "        return 0\n",
    "\n",
    "        # Antall elementer i en kategori\n",
    "    def catcount(self, cat):\n",
    "        if cat in self.cc:\n",
    "            return float(self.cc[cat])\n",
    "        return 0\n",
    "\n",
    "        # Antall elementer\n",
    "    def totalcount(self):\n",
    "        return sum(self.cc.values())\n",
    "\n",
    "        # Alle kategorier\n",
    "    def categories(self):\n",
    "        return self.cc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening\n",
    "\n",
    "`train` tar inn et dokument og den tilhørende klassen, og oppdaterer `fc` og `cc` i klassifikatoren i henhold til dataen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def train(self, item, cat):\n",
    "        features = self.getfeatures(item)\n",
    "\n",
    "        for f in features:\n",
    "            self.incf(f, cat)\n",
    "\n",
    "        self.incc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nå har vi en klassifikator med en treningsfunksjon som holder styr på hvor mange ganger en `feature` forekommer i hver `klasse/kategori`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sannsynlighet\n",
    "\n",
    "Vi beregner `P (f|c)`, altså antall ganger denne `featuren` har forekommet i klassen delt på antall elementer i klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def fprob(self, f, cat):\n",
    "        if self.catcount(cat) == 0:\n",
    "            return 0\n",
    "\n",
    "        return self.fcount(f, cat)/self.catcount(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dersom et ord først havner i klassen `positiv`, vil `fprob` plutselig gi en sjanse på 0 for at dette ordet vil havne i klassen `negativ` senere. For å komme seg rundt dette problemet, velger vi en `prior probability`, der vi setter en foreløpig sannsynlighet for klassene. Vi lager en funksjon for å vekte det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def weightedprob(self, f, cat, prf, weight=1.0, ap=0.5):\n",
    "        # Vi velger 0.5 som prior probability\n",
    "        \n",
    "        # Kalkuler sannsynlighet\n",
    "        basicprob = prf(f, cat)\n",
    "\n",
    "        # Tell antall ganger denne featuren har forekommet i kategoriene\n",
    "        totals = sum([self.fcount(f, c) for c in self.categories()])\n",
    "\n",
    "        # Kalkuler det vektede snittet\n",
    "        bp = ((weight * ap) + (totals * basicprob)) / (weight + totals)\n",
    "        return bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naïve Bayes-klassifikator\n",
    "\n",
    "Nå skal vi bruke naïve Bayes for å klassifisere dokumenter. Vi lager først en funksjon for å regne ut P (dokument|klasse), og siden vi antar at featurene er uavhengige, er dette det samme som P (ord1|klasse) * P (ord2|klasse) * ...\n",
    "\n",
    "Vi lager en subklasse av `classifier`, `naivebayes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naivebayes(classifier):\n",
    "    def docprob(self, item, cat):\n",
    "        features = self.getfeatures(item)\n",
    "        \n",
    "        # Ganger sammen sannsynlighetene for alle featurene/ordene\n",
    "        p = 1\n",
    "        for f in features:\n",
    "            p *= self.weightedprob(f, cat, self.fprob)\n",
    "            return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan nå beregne `P(dokument|klasse)`, men for å klassifisere nye dokumenter trenger vi `P(klasse|dokument`. Heldigvis hjelper Bayes´ teorem oss her:\n",
    "\n",
    "`P(klasse|dokument) = (P(dokument|klasse) * P(klasse)) / P(dokument)`\n",
    "\n",
    "Og siden vi deler på `P(dokument)` for alle klassene, kan vi fjerne denne. Vi beregner `P(klasse|dokument)` slik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def prob(self, item, cat):\n",
    "        catprob = self.catcount(cat) / self.totalcount()\n",
    "        docprob = self.docprob(item, cat)\n",
    "        return docprob * catprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify\n",
    "\n",
    "Det eneste vi mangler nå, er å beregne `P(klasse|dokument)` for hver klasse, så finne vi ut hvor dokumentet hører hjemme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def classify(self, document):\n",
    "        probs = {}\n",
    "\n",
    "        # Finn klassen med høyest sannsynlighet\n",
    "        max = 0.0\n",
    "\n",
    "        for cat in self.categories():\n",
    "            probs[cat] = self.prob(document, cat)\n",
    "            if probs[cat] > max:\n",
    "                max = probs[cat]\n",
    "                best = cat\n",
    "\n",
    "        return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les inn data\n",
    "\n",
    "Hver linje i treningsfilen inneholder et tall (1 eller 0) og en setning. 1 indikerer at setningen er positiv og 0 indikerer at setningen er negativ. Her er et par eksempler fra filen:\n",
    "\n",
    "```\n",
    "1\tHey I loved The Da Vinci Code!..\n",
    "1\tMission Impossible III was awesome.\n",
    "0\tI hate Harry Potter, it's retarted, gay and stupid and there's only one Black guy...\n",
    "\n",
    "```\n",
    "\n",
    "Les inn treningsdataen og klassifiser nye dokumenter slik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_training_data(_file):\n",
    "    with open(_file) as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    data = [line.strip().split('\\t') for line in content]\n",
    "\n",
    "    return(data)\n",
    "\n",
    "def train_from_file(classifier, _file=\"training.txt\"):\n",
    "    data = retrieve_training_data(_file)\n",
    "\n",
    "    for line in data:\n",
    "        classifier.train(line[1], 'positive' if line[0] == '1' else 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Så kan du trene nye dokumenter slik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = naivebayes(getwords)\n",
    "train_from_file(classifier)\n",
    "\n",
    "print(classifier.classify('i love harry potter'))\n",
    "print(classifier.classify('i hate trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgaver\n",
    "\n",
    "1. Istedenfor å trene på hele filen, bruk 80% av den på trening og 20% av den til testing. Hvor høy precision og recall får du?\n",
    "\n",
    "2. Kan du finne en måte å håndtere negering på? Hvordan påvirker det precision og recall?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
